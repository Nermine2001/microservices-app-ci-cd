# ðŸ—ï¸ Architecture Technique DÃ©taillÃ©e

Documentation complÃ¨te de l'architecture de l'application microservices avec IA et CI/CD.

---

## ðŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture des microservices](#architecture-des-microservices)
3. [Technologies utilisÃ©es](#technologies-utilisÃ©es)
4. [Pipeline CI/CD](#pipeline-cicd)
5. [SÃ©curitÃ©](#sÃ©curitÃ©)
6. [Performance et scalabilitÃ©](#performance-et-scalabilitÃ©)
7. [Monitoring et logs](#monitoring-et-logs)

---

## ðŸŽ¯ Vue d'ensemble

### Objectif du Projet

CrÃ©er une application d'analyse de sentiment basÃ©e sur l'IA avec une architecture microservices moderne, incluant:
- Conteneurisation Docker
- Pipeline CI/CD automatisÃ©
- Tests automatisÃ©s
- DÃ©ploiement continu

### Principes Architecturaux

- **SÃ©paration des responsabilitÃ©s**: Chaque microservice a un rÃ´le unique
- **IndÃ©pendance**: Les services peuvent Ãªtre dÃ©ployÃ©s indÃ©pendamment
- **ScalabilitÃ©**: Chaque service peut Ãªtre scalÃ© horizontalement
- **RÃ©silience**: Failure isolation entre les services
- **ObservabilitÃ©**: Logs centralisÃ©s et health checks

---

## ðŸ”§ Architecture des Microservices

### Diagramme d'Architecture

```
                        Internet/Users
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Load Balancer â”‚
                    â”‚   (Nginx/HAProxy)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Frontend         â”‚  â”‚   Jenkins    â”‚
         â”‚   React + Nginx    â”‚  â”‚   CI/CD      â”‚
         â”‚   Port: 3000       â”‚  â”‚   Port: 8080 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Backend API      â”‚
         â”‚   Node.js/Express  â”‚
         â”‚   Port: 5000       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   AI Service       â”‚
         â”‚   Python + ML      â”‚
         â”‚   Port: 8000       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Communication entre Services

```
Frontend  â”€â”€HTTPâ”€â”€â–¶  Backend API  â”€â”€HTTPâ”€â”€â–¶  AI Service
          â—€â”€â”€â”€â”€â”€â”€â”€â”€           â—€â”€â”€â”€â”€â”€â”€â”€â”€

Format: JSON
Protocol: REST API
Timeout: 30s
Retry: 3 attempts
```

---

## ðŸŽ¨ Microservice 1: Frontend

### Technologies
- **Framework**: React 18
- **Build Tool**: Create React App
- **HTTP Client**: Axios
- **Web Server**: Nginx
- **Styling**: CSS3 avec gradients

### ResponsabilitÃ©s
- Interface utilisateur
- Formulaire d'analyse
- Affichage des rÃ©sultats
- Visualisation des statistiques
- Historique des analyses

### Structure des Fichiers
```
frontend/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ nginx.conf
â”œâ”€â”€ package.json
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html
â””â”€â”€ src/
    â”œâ”€â”€ App.jsx          # Composant principal
    â”œâ”€â”€ App.css          # Styles
    â””â”€â”€ index.js         # Point d'entrÃ©e
```

### API Endpoints UtilisÃ©s
```javascript
GET  /health                  # Health check
POST /api/analyze            # Analyser un texte
POST /api/batch-analyze      # Analyser plusieurs textes
GET  /api/history            # RÃ©cupÃ©rer l'historique
GET  /api/stats              # RÃ©cupÃ©rer les statistiques
```

### Gestion d'Ã‰tat
```javascript
- text: String              # Texte Ã  analyser
- result: Object           # RÃ©sultat de l'analyse
- loading: Boolean         # Ã‰tat de chargement
- error: String|null       # Messages d'erreur
- history: Array           # Historique des analyses
- stats: Object            # Statistiques globales
```

### Build Process
```dockerfile
# Stage 1: Build
FROM node:20-alpine AS build
COPY package*.json ./
RUN npm ci
COPY src/ ./src/
RUN npm run build

# Stage 2: Production
FROM nginx:alpine
COPY --from=build /app/build /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
```

---

## âš™ï¸ Microservice 2: Backend API

### Technologies
- **Runtime**: Node.js 20
- **Framework**: Express.js
- **HTTP Client**: Axios
- **Logging**: Morgan

### ResponsabilitÃ©s
- Orchestration des requÃªtes
- Gestion de l'historique (en mÃ©moire)
- Calcul des statistiques
- Proxy vers le service IA
- Gestion des erreurs

### Structure des Fichiers
```
backend-api/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â””â”€â”€ src/
    â””â”€â”€ server.js        # Serveur Express
```

### Endpoints API

#### POST /api/analyze
```javascript
Request:
{
  "text": "Texte Ã  analyser",
  "userId": "optional-user-id"
}

Response:
{
  "id": "1234567890",
  "timestamp": "2025-10-07T10:30:00Z",
  "userId": "user-123",
  "text": "...",
  "sentiment": {
    "label": "positive",
    "score": 0.95,
    "compound": 0.8,
    "details": {...}
  },
  "emotions": [...]
}
```

#### GET /api/history
```javascript
Query Parameters:
- limit: Number (default: 20)

Response:
{
  "total": 150,
  "limit": 20,
  "data": [...]
}
```

#### GET /api/stats
```javascript
Response:
{
  "totalAnalyses": 150,
  "sentimentDistribution": {
    "positive": 80,
    "negative": 40,
    "neutral": 30
  },
  "averageConfidence": 0.85
}
```

### Gestion des Erreurs
```javascript
// Timeout handling
timeout: 30000  // 30 secondes

// Retry logic
maxRetries: 3
retryDelay: 1000  // 1 seconde

// Error codes
400: Bad Request
503: Service Unavailable (AI Service down)
500: Internal Server Error
```

---

## ðŸ¤– Microservice 3: AI Service

### Technologies
- **Language**: Python 3.11
- **Framework**: Flask
- **ML Libraries**:
  - NLTK (VADER) - Sentiment Analysis
  - Transformers (HuggingFace) - Emotion Detection
  - PyTorch - Deep Learning Backend
- **Server**: Gunicorn

### ResponsabilitÃ©s
- Analyse de sentiment (positif/nÃ©gatif/neutre)
- DÃ©tection d'Ã©motions (joie, tristesse, colÃ¨re, etc.)
- Traitement du langage naturel
- Scoring de confiance

### ModÃ¨les UtilisÃ©s

#### VADER (Valence Aware Dictionary and sEntiment Reasoner)
```python
Model: NLTK VADER Lexicon
Type: Rule-based
Speed: Very Fast (~0.01s per text)
Accuracy: 80-85%
Language: English (primarily)

Scores:
- positive: 0.0 to 1.0
- neutral: 0.0 to 1.0
- negative: 0.0 to 1.0
- compound: -1.0 to +1.0
```

#### DistilRoBERTa (Emotion Classification)
```python
Model: j-hartmann/emotion-english-distilroberta-base
Type: Transformer (BERT-based)
Speed: Medium (~0.5s per text)
Accuracy: 90-95%
Emotions: joy, sadness, anger, fear, surprise, disgust, neutral

Max Input: 512 tokens
Output: Probability distribution over emotions
```

### Structure des Fichiers
```
ai-service/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ src/
    â””â”€â”€ app.py           # Application Flask
```

### Endpoints API

#### POST /analyze
```python
Request:
{
  "text": "Your text here"
}

Response:
{
  "text": "Your text here",
  "sentiment": {
    "label": "positive",
    "score": 0.95,
    "compound": 0.8642,
    "details": {
      "positive": 0.75,
      "neutral": 0.20,
      "negative": 0.05
    }
  },
  "emotions": [
    {"label": "joy", "score": 0.92},
    {"label": "surprise", "score": 0.05},
    ...
  ],
  "metadata": {
    "text_length": 50,
    "model": "VADER + DistilRoBERTa"
  }
}
```

#### POST /batch-analyze
```python
Request:
{
  "texts": ["text1", "text2", ...]
}

Response:
{
  "results": [
    {"index": 0, "text": "...", "sentiment": "positive", ...},
    ...
  ],
  "total": 10
}
```

### Performance Optimization
```python
# Model loading
- Models loaded once at startup
- Kept in memory for fast inference

# Batch processing
- Up to 50 texts per request
- Parallel processing for batch

# Caching
- Results cached for 1 hour
- Cache key: hash(text)
```

---

## ðŸ”„ Pipeline CI/CD

### Architecture Jenkins

```
GitHub Push
     â”‚
     â–¼
GitHub Webhook
     â”‚
     â–¼
Jenkins Trigger
     â”‚
     â”œâ”€â–¶ Checkout Code
     â”‚
     â”œâ”€â–¶ Build (Parallel)
     â”‚   â”œâ”€ AI Service
     â”‚   â”œâ”€ Backend API
     â”‚   â””â”€ Frontend
     â”‚
     â”œâ”€â–¶ Test (Parallel)
     â”‚   â”œâ”€ Unit Tests
     â”‚   â”œâ”€ Integration Tests
     â”‚   â””â”€ Lint
     â”‚
     â”œâ”€â–¶ Security Scan
     â”‚   â””â”€ Trivy (optional)
     â”‚
     â”œâ”€â–¶ Push to Registry
     â”‚   â””â”€ Docker Hub/Local
     â”‚
     â”œâ”€â–¶ Deploy
     â”‚   â””â”€ Docker Compose
     â”‚
     â””â”€â–¶ Health Check
         â””â”€ Verify Services
```

### Ã‰tapes du Pipeline

#### 1. Checkout
```groovy
stage('Checkout') {
  steps {
    checkout scm
    sh 'git rev-parse --short HEAD > .git/commit-id'
  }
}
```

#### 2. Build (Parallel)
```groovy
stage('Build Images') {
  parallel {
    stage('AI Service') { ... }
    stage('Backend API') { ... }
    stage('Frontend') { ... }
  }
}
```

#### 3. Test
```groovy
stage('Test') {
  steps {
    sh 'jenkins/scripts/test.sh'
  }
}
```

#### 4. Deploy
```groovy
stage('Deploy') {
  when { branch 'main' }
  steps {
    sh 'jenkins/scripts/deploy.sh'
  }
}
```

### Temps d'ExÃ©cution Typiques
```
Checkout:        10-30s
Build:           5-10 min
Test:            1-2 min
Security Scan:   2-5 min
Deploy:          1-2 min
Health Check:    30s

Total:           10-20 min
```

---

## ðŸ”’ SÃ©curitÃ©

### Mesures ImplÃ©mentÃ©es

#### 1. Conteneurs
```dockerfile
# Non-root user
USER node  # ou www-data

# Read-only filesystem
read_only: true

# No privileged mode
privileged: false
```

#### 2. RÃ©seau
```yaml
# Network isolation
networks:
  - app-network  # Internal only

# Port exposure
ports:
  - "3000:3000"  # Frontend only
  - "127.0.0.1:5000:5000"  # Backend internal
```

#### 3. Headers de SÃ©curitÃ©
```nginx
# Nginx configuration
add_header X-Frame-Options "SAMEORIGIN";
add_header X-Content-Type-Options "nosniff";
add_header X-XSS-Protection "1; mode=block";
```

#### 4. Input Validation
```javascript
// Backend validation
- Max text length: 5000 characters
- Required fields check
- SQL injection prevention
- XSS protection
```

#### 5. CORS Policy
```javascript
cors({
  origin: ['http://localhost:3000'],
  methods: ['GET', 'POST'],
  credentials: true
})
```

---

## ðŸ“ˆ Performance et ScalabilitÃ©

### MÃ©triques de Performance

#### Temps de RÃ©ponse
```
Frontend Load:     < 2s
API Response:      < 100ms
AI Analysis:       < 2s
Total Round-trip:  < 3s
```

#### Throughput
```
AI Service:        ~20 requests/second
Backend API:       ~100 requests/second
Frontend:          ~500 concurrent users
```

### StratÃ©gies de ScalabilitÃ©

#### Horizontal Scaling
```yaml
# Docker Compose
services:
  ai-service:
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 2G
```

#### Load Balancing
```nginx
upstream ai_backend {
  server ai-service-1:8000;
  server ai-service-2:8000;
  server ai-service-3:8000;
}
```

#### Caching
```javascript
// Response caching
Cache-Control: public, max-age=3600

// Redis (future enhancement)
cache.set(hash(text), result, 3600)
```

---

## ðŸ“Š Monitoring et Logs

### Health Checks

#### Frontend
```bash
GET /
Status: 200 OK
Content-Type: text/html
```

#### Backend API
```bash
GET /health
Response:
{
  "status": "healthy",
  "service": "backend-api",
  "timestamp": "2025-10-07T10:30:00Z"
}
```

#### AI Service
```bash
GET /health
Response:
{
  "status": "healthy",
  "service": "ai-service",
  "model_loaded": true
}
```

### Logging Strategy

#### Log Levels
```
ERROR:   Critical failures
WARN:    Potential issues
INFO:    Important events
DEBUG:   Detailed information
```

#### Log Format
```json
{
  "timestamp": "2025-10-07T10:30:00Z",
  "level": "INFO",
  "service": "backend-api",
  "message": "Analyse completed",
  "duration": "1.5s",
  "status": "success"
}
```

#### Log Aggregation
```bash
# Docker logs
docker-compose logs -f

# Centralized (future)
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Grafana Loki
- Splunk
```

---

## ðŸš€ Ã‰volutions Futures

### Phase 2
- [ ] Kubernetes deployment
- [ ] Database persistence (PostgreSQL/MongoDB)
- [ ] Redis caching
- [ ] User authentication (JWT)
- [ ] Rate limiting

### Phase 3
- [ ] Prometheus + Grafana monitoring
- [ ] Distributed tracing (Jaeger)
- [ ] Message queue (RabbitMQ/Kafka)
- [ ] Multi-language support
- [ ] Advanced ML models

### Phase 4
- [ ] Microservices mesh (Istio)
- [ ] Auto-scaling (HPA)
- [ ] Disaster recovery
- [ ] Multi-region deployment
- [ ] A/B testing framework

---

## ðŸ“š RÃ©fÃ©rences

### Documentation
- Docker: https://docs.docker.com
- Kubernetes: https://kubernetes.io/docs
- Jenkins: https://www.jenkins.io/doc
- React: https://react.dev
- Flask: https://flask.palletsprojects.com

### ModÃ¨les ML
- VADER: https://github.com/cjhutto/vaderSentiment
- HuggingFace: https://huggingface.co/j-hartmann/emotion-english-distilroberta-base

---

**DerniÃ¨re mise Ã  jour**: 7 Octobre 2025